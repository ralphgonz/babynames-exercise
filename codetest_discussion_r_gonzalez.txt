Capital One Labs Coding Challenge -- Results

Ralph Gonzalez 2015



Part 1: Model building on a synthetic dataset

Ideally I would know more about the underlying system. Otherwise I am more likely to try multiple models and risk overfitting the data. 

The problem initially looked suitable for linear 
regression, so I started using Perl and it's Statistics::Regression module. It might have been better to analyze the data more in advance, using R or similar software.

There are 4 categorical non-numeric columns. In order to apply a regression model I replaced each categorical variable with multiple dummy variables coded as 0/1. 

Unfortunately the linear regression package could not handle this dataset, possibly due to collinearity among the columns?

Instead, I coded a k-nearest neighbors (5) algorithm using normalized columns. Though less powerful, I think a non-parametric approach is less sensitive to distributional assumptions. This implementation is inefficient since it keeps the entire training set in memory and exhaustively passes through this data for each test case. A clustering algorithm might avoid this issue. Another weakness of this implementation is the use of unweighted, normalized columns. A decision-tree approach might be more powerful.


